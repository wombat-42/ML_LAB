{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jY3k3fll4RYT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dea04567-7be4-4570-b5fc-5aa37659c702"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 83.27%\n",
            "Confusion Matrix:\n",
            "[[7003  411]\n",
            " [1223 1132]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('sample_data/income.csv')\n",
        "\n",
        "# Define features and target variable\n",
        "X = data.drop(columns=['income_level'])\n",
        "y = data['income_level']\n",
        "\n",
        "# Split the dataset into 80% training and 20% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build AdaBoost model (default base estimator is a DecisionTreeClassifier with max_depth=1)\n",
        "ada_model = AdaBoostClassifier(n_estimators=50, learning_rate=1.0, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "ada_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = ada_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split dataset into 80% training and 20% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define n_estimators values and learning rates for fine-tuning\n",
        "n_estimators_values = [50, 100, 150]\n",
        "learning_rates = [0.1, 0.5, 1.0]\n",
        "\n",
        "# Results with DecisionTreeClassifier as base estimator\n",
        "print(\"Results with DecisionTreeClassifier as base estimator:\")\n",
        "for n_estimators in n_estimators_values:\n",
        "    for learning_rate in learning_rates:\n",
        "        ada_boost_dt = AdaBoostClassifier(\n",
        "            n_estimators=n_estimators,\n",
        "            learning_rate=learning_rate,\n",
        "            random_state=42\n",
        "        )\n",
        "        ada_boost_dt.fit(X_train, y_train)\n",
        "        y_pred = ada_boost_dt.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        print(f\"n_estimators={n_estimators}, learning_rate={learning_rate} -> Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Results with LogisticRegression as base estimator\n",
        "# Using Logistic Regression as a weak learner in AdaBoost is not directly supported, so we will skip this\n",
        "print(\"\\nLogistic Regression cannot be used as a base estimator directly in AdaBoost.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGsmFkQR46x5",
        "outputId": "ba81946a-903a-4e41-ff41-87f8499df693"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results with DecisionTreeClassifier as base estimator:\n",
            "n_estimators=50, learning_rate=0.1 -> Accuracy: 100.00%\n",
            "n_estimators=50, learning_rate=0.5 -> Accuracy: 96.67%\n",
            "n_estimators=50, learning_rate=1.0 -> Accuracy: 93.33%\n",
            "n_estimators=100, learning_rate=0.1 -> Accuracy: 100.00%\n",
            "n_estimators=100, learning_rate=0.5 -> Accuracy: 100.00%\n",
            "n_estimators=100, learning_rate=1.0 -> Accuracy: 93.33%\n",
            "n_estimators=150, learning_rate=0.1 -> Accuracy: 100.00%\n",
            "n_estimators=150, learning_rate=0.5 -> Accuracy: 96.67%\n",
            "n_estimators=150, learning_rate=1.0 -> Accuracy: 93.33%\n",
            "\n",
            "Logistic Regression cannot be used as a base estimator directly in AdaBoost.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split into 80% train and 20% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Hyperparameter values\n",
        "n_estimators_values = [50, 100, 150]\n",
        "learning_rates = [0.1, 0.5, 1.0]\n",
        "\n",
        "# Using DecisionTreeClassifier\n",
        "print(\"Results with DecisionTreeClassifier as base estimator:\")\n",
        "for n in n_estimators_values:\n",
        "    for lr in learning_rates:\n",
        "        model = AdaBoostClassifier(\n",
        "            estimator=DecisionTreeClassifier(max_depth=1),\n",
        "            n_estimators=n,\n",
        "            learning_rate=lr,\n",
        "            random_state=42\n",
        "        )\n",
        "        model.fit(X_train, y_train)\n",
        "        preds = model.predict(X_test)\n",
        "        acc = accuracy_score(y_test, preds)\n",
        "        print(f\"n_estimators={n}, learning_rate={lr} -> Accuracy: {acc * 100:.2f}%\")\n",
        "\n",
        "# Using LogisticRegression\n",
        "print(\"\\nResults with LogisticRegression as base estimator:\")\n",
        "for n in n_estimators_values:\n",
        "    for lr in learning_rates:\n",
        "        model = AdaBoostClassifier(\n",
        "            estimator=LogisticRegression(max_iter=1000, random_state=42),\n",
        "            n_estimators=n,\n",
        "            learning_rate=lr,\n",
        "            random_state=42\n",
        "        )\n",
        "        model.fit(X_train, y_train)\n",
        "        preds = model.predict(X_test)\n",
        "        acc = accuracy_score(y_test, preds)\n",
        "        print(f\"n_estimators={n}, learning_rate={lr} -> Accuracy: {acc * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd_-JDFa5AnQ",
        "outputId": "4b16bc30-1543-48ed-9d64-df8cf7f538e1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results with DecisionTreeClassifier as base estimator:\n",
            "n_estimators=50, learning_rate=0.1 -> Accuracy: 100.00%\n",
            "n_estimators=50, learning_rate=0.5 -> Accuracy: 96.67%\n",
            "n_estimators=50, learning_rate=1.0 -> Accuracy: 93.33%\n",
            "n_estimators=100, learning_rate=0.1 -> Accuracy: 100.00%\n",
            "n_estimators=100, learning_rate=0.5 -> Accuracy: 100.00%\n",
            "n_estimators=100, learning_rate=1.0 -> Accuracy: 93.33%\n",
            "n_estimators=150, learning_rate=0.1 -> Accuracy: 100.00%\n",
            "n_estimators=150, learning_rate=0.5 -> Accuracy: 96.67%\n",
            "n_estimators=150, learning_rate=1.0 -> Accuracy: 93.33%\n",
            "\n",
            "Results with LogisticRegression as base estimator:\n",
            "n_estimators=50, learning_rate=0.1 -> Accuracy: 100.00%\n",
            "n_estimators=50, learning_rate=0.5 -> Accuracy: 100.00%\n",
            "n_estimators=50, learning_rate=1.0 -> Accuracy: 93.33%\n",
            "n_estimators=100, learning_rate=0.1 -> Accuracy: 100.00%\n",
            "n_estimators=100, learning_rate=0.5 -> Accuracy: 100.00%\n",
            "n_estimators=100, learning_rate=1.0 -> Accuracy: 93.33%\n",
            "n_estimators=150, learning_rate=0.1 -> Accuracy: 100.00%\n",
            "n_estimators=150, learning_rate=0.5 -> Accuracy: 100.00%\n",
            "n_estimators=150, learning_rate=1.0 -> Accuracy: 93.33%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TXB_DX105Hup"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}